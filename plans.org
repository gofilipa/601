* class plans
** week 1, introduction to the course
Agenda:
- Syllabus day
- introductions, myself and you
- overview of the course, assignments, readings
- break
- talk about reading for grad school
- talk about information studies and unpack "information"

Myself
- Filipa Calado, call me Professor.
- Background in Literature, Queer studies, Digital Studies
- Using technology to study queer literature (dissertation)
- Now interested in language broadly, how meaning changes across
  different forms of language, how these are affected by technology
  (recently things like AI) and how to use tech to study language.
- Teaching for 8 years across NYC universities, NYU, New School,
  CUNY; classes on writing, critical thinking, data science, creative
  coding. So a wide range.
- First semseter teaching at Pratt, am very excited.

The course
- INFO 601:
  - Introduction to the field of "information studies"
    - broad term, encompasses work by librarians, analysts, cultural
      heritage curators, managers
  - Exploring the question, what is information? How does form affect
    meaning? Source, platform, speaker, audience, material substrate.
  - Thinking critically about information production
  - Different specializations and jobs available to info practitioners
  - Also, an introduction to graduate school, to thinking, reading,
    and writing critically.
    - how to insert yourself into an academic/professional
      conversation.
  - Finally, we take a critical perspective that pays attention to
    structures of power and how they affect all aspects of
    information.
- Assignments:
  - readings every week
  - posting on discussion board every week
  - some 'fieldwork' (attending 2 events and writing about it)
  - final project (book review) highly scaffolded
  - class discussion major focus.

Will go through the syllabus in more detail. But for now let's do
introductions.

Around the room, say your name, program, and best content you've
consumed lately.
- Professor Calado, I'm faculty, no program. But I would have been in
  Data Analysis probably; and House of the Dragon. So good. Well
  paced.

Syllabus Review
- Go over:
  - Course Info
  - Instructor Info
  - Course Description
  - Course Goals
  - Learning Outcomes
  - Sources, Canvas
  - Format - discussion
- Assignments
  - Discussion posts on canvas, 3 times per week, 2-3 sentences per
    post.
  - Fieldwork
    - 2x/semester, reports due on Nov 26 on Canvas, and you will also
      share them in class the week that you do them. 5 minutes max, so
      like 2 page report.
    - gets you to experience the field in practice, attend events like
      talks and lectures
    - can be virtual
    - one of them should be the Ethics and Technology forum end of
      October, we will be reading the speaker's book anyway.
    - ask me if you are not sure if something counts.
    - by november 26
  - AI activity
    - due in 2 weeks, 1000 words, or 3 pages max (double spaced)
    - options include
      - talk to a chatbot
      - analyze a TOS
      - review a court case
      - do an analysis of your chosen activity, submit online, and we
        will spend an entire day sharing and discussing them.
  - Book Review
    - final project
    - highly scaffolded, will work in parts, proposal, drafts.
    - choose a book from the last 3 years and review it. Make a case
      for older books
    - summarize argument, significance, context.
    - about 12 pages.
    - last month of the semseter will be focused on this assignment.
  - Course Schedule
    - weeks are broken up into "themes" in bold
    - example: next week is AI, the follwing is being online
    - Also weeks that pertain to different programs in the dept, like
      design and archives
    - do not read ahead
    - questions?

BREAK

How to read for grad school
- how do you read longer things? More academic things?
- what strategies (if any) do you use?
- is there an order or way to go about it?
- Now, read the article in 10 minutes, while thinking about:
  - Do these seem like good strategies, why or why not?
  - What have you done that works for you, and what do you think
    wouldn't work?
- share & discuss


"Information" freewrite and discussion
- 5 minutes
  - Where do you get your information? Make a list.
  - How do you determine if it's good or bad information? Credible?
    How important is this step?
  - What is the biggest challenge to consuming information in today's
    world?
- pair & share

Wrap up
- remember readings and discussion posts!

** week 2, artificial intelligence

Agenda
- topic today: artificial intelligence
- some writing about the readings
- some talking about the readings
- break
- talking about AI, maybe going into depth about how it works
- some prep for next week's AI activity

*** introductions 10 min
Name, program, one thing you want to learn how to do. 

*** freewrite 10 min
- What idea or detail from the reading was most interesting to you?
  What do you find so compelling about it? Why is it important?

*** share in groups of 2 or 3 people 10 minutes
Each person shares what they wrote.

Then, as a group, you decide one point to share with the class.

*** reframe your chosen point as a question 5 minutes
But, before you share, try to re-write your point as a question. You
want to write a question that is open-ended (not a yes/no question),
and that would inspire different kinds of responses.

For example, if your interest is something like, "the difficulty of
removing bias and discriminatory views from the data used to train AI
chatbots," you might re-frame the question like, "what are actual ways
that we can make AI training datasets less discriminatory and biased?"
OR you might go deeper to ask something like, "if we cannot remove
bias from datasets, is it possible to use AI tools in an ethical way?
How could we do that?"

Try to write questions that inspire curiosity and different points of
view. This is actually hard to do, so just try your best!

*** share 10 minutes
Go around the room and share your questions, writing them down on the
googledoc.

Then, I (filipa) choose a question to start the conversation. We can
take a minute or so to think about responding before discussion.

*** discussion 45 min

IFLA (2023). “Generative AI for Library and Information Professionals
(draft), https://www.ifla.org/generative-ai
- IFLA: Interational Federation of Library Associations and
  Institutions
- What is it about?
  - Guide on what is Generative AI for people who work in information
    professions and lack technical background.
  - has excellent sources cited.
  - emphasizes ethics and mis/dis-information issues:
    - bias, hallucination
    - overwhelming amounts of information
    - lack of transparency of how they are made
    - lack of privacy for users
    - issue of copyright and stealing the training data
    - can eliminate jobs, and put people w/o access at disadvantage
    - capitalism, big tech runs it.

- Discuss:
  - how do the "good" qualities of AI compare with the "bad"?
  - how can or should we use AI if it's not ethical?
    - maybe we shouldn't?
    - use it as part of a workflow, for summarizing, describing. Even
      drafting. But as /part/ of work and not the whole.

Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021,
March). On the Dangers of Stochastic Parrots: Can Language Models Be
Too Big?. In Proceedings of the 2021 ACM conference on fairness,
accountability, and transparency (pp. 610-623).
https://doi.org/10.1145/3442188.3445922
- who?
  - Bender, comp linguist scholar at UWash
  - Gebru, former Google AI Ethics researcher, now helps to lead DAIR
  - Smitchell, former Google AI Ethics researcher, now at Huggingface

- published in 2021, way ahead of its time (ChatGPT came out Fall
  2022).

- What is the main argument?
  - Ethical implications of one aspect about LLMs: SIZE
    - environmental effects
    - socialeconomic effects - marginalized people
    - bias and discrimination - data
    - human interpretation of text as meaningful leads to
      misinformation/misinterpretation

- "Unfathomable training data"
  - "size doesn't gaurantee diversity"
    - we assume large size means more representation, but that's not
      the case.
    - statistical methods amplify what is most frequent. They suppress
      outliers.
    - we get something that perpetuates a majority view: users who are
      young, male, from developed countries.
  - we cannot automate the removal of bias
    - list of dirty, naughty, etc. words.
    - removing whole pages containing bad words overlooks context,
      nuance, reclamation, explanation.
  - what is the solution?
    - avoid "documentation debt" by budgeting to make high quality
      datasets.
      - document motivations behind data collection
      - document process of cleaning
      - "pre-mortem" - explore hypothetical failures
      - "value sensitive design" - make sure stakeholder values are
        supported from the outset.

- "communicative intent"
  - to communicate, we need to guess the intention of the speaker.
  - humans see meaning in everything, we have to impose meaning. 


Read Princeton University Library Libguide on Generative AI’s
“Copyright” page,
https://libguides.princeton.edu/c.php?g=1341922&p=10257371.
- Authors Guild vs OpenAI & Microsoft
  - plaintiffs allege that OpenAI stole content in a way that affects
    creators' livelihoods.
  - defendants say it's "Fair Use" due to highly transformative nature
    of LLMs. That it goes beyond the jurisdiction of copyright law,
    we need new ways of litigating these objects.

- NYT vs OpenAi
  - NYT says training on their content is stealing
  - OpenAI says no, that it only trained to get a sense of language.
    That NYT doesn't own language forms.


Watch “What is AI? Part 1, with Meredith Whittaker | AI Now Salons” on
youtube, https://www.youtube.com/watch?v=US8xKmD7G1s
- Former google employee, now speaks out against Big Tech; CEO of
  Signal messaging app
- What is her argument?
  - AI companies are not only concentrating power, but are also a
    result of concentrated power. This is a structural problem.
  - "how do you democratize something that was created by centralized
    power?"
    - the compute required means only a few can host the models.
      Everyone else must rent it.
- She's putting forth a certain narrative about how AI came to be.
  - Privatization of the internet, was defense, academics, now
    private.
    - Surveillance business model, for advertizing
    - Now big tech sells server space, because they have the
      infrastructure for it. They also have the data. 
- What got her started thinking about the dangers of AI?
  - Harvard researcher came in talking about using AI to predict
    genocide. What is genocide in data? 
- What are the solutions?

First two sections, “What is compute and why does it matter?” & “How
is the demand for compute shaping AI development”, in Jai Vipra and
Sarah Myers West, “Computational Power and AI,” AI Now Institute,
September 27, 2023,
https://ainowinstitute.org/publication/policy/compute-and-ai.
- who is AI NOW?
  - research group, institute, on AI and AI policy. Explores dangers
    of AI and big tech on society, environment, economy.
- what is the main message?
  - compute is computational power
  - how does the industry concentration in compute affect the way that
    AI tech is being produced?
    - companies act quickly to protect their dominance, racing to
      release products before they are ready or safe.
    - further expands power and reach
    - money is bottom line
  - "compute stack" of hardware and software and infrastructure. 

*** break 15 min

*** continue discussion 30 min

*** how does chatgpt work? 20 min
**** How does ChatGPT work?
How does it know what to respond when someone asks it a question?

More specifically, how does it know what language to generate, what
words follow other words?
- by prediction.
- it learns by reading. Gains an understanding of language from
  processing massive amounts of text, deriving patterns.

It builds a kind of model for each word, what words tend to surround
that word in a sentence.
- key idea here is "context"

This model for meaning is called a "word vector" '

**** Word Vectors
Word Vectors:
- numerical representation of words. Words represented by numbers, a
  list of numbers.
- Each number represents that word's relation to another word, in the
  form of a probability. How they are related.
  - here we have a word, "Artificial" and related words, each with
    similarity scores.
  - the similarity scores together comprise the vector.

Let's take the word "cat" and "dog" 
- furry, milk, bone, lick
  
This is how we turn language, the semantics and expressivity of
language, into something a computer can understand.

Every word becomes a dot in graphical space, and is represented by a
list of numbers, very long. 

**** King - Man + Woman = Queen
Not only do computers process language, but they can do math with it.
- Each word is represented by a series of numbers,
  with each of those numbers representing it's relationship to another
  word. How closely they are related.

Linear algebra, matrix algebra.

Calculus.

Cosine similarity and Euclidean distance. 

Read more in the Word2Vec Paper.

*** introduce AI activity
System probe, privacy audit, or legal opinion.

Review the requirements for each, and use the rest of class time to
get started on the assignment. 

** week 3, artificial intelligence, continued
Agenda
- discuss AI activity
- continue discussions from last week's readings
- start to talk about final project, going to move up some of the work
  on that project, brainstorming things
- weekly posts -- do 2 posts per week. You guys are writing too much!
  3-4 sentences per post.

Introductions, 10 min
- What was your dream job as a kid?
- Favorite disney movie?

Discuss AI Activity in Groups, 30 min
- split up by area: probe, audit, legal
- 20-25min: share what you did with your group, go into some detail
  about the questions you were asking or thinking about
  - what did you find most intriguing or interesting about the activity?
  - what's one question you have at the end of the process? In other
    words, where would you go from here?
- 5-10 min: together, come up with one discussion question to share
  with the class.

Share out, 30 - 45 min
- write down the questions on the board
- anybody want to share their experiences?
- if nothing, point to the "can we ever really remove bias, and what
  would that look like?"
  - explain what happened with the list of dirty words.
  - is this a problem, or no?

BREAK - 20 minutes

Freewrite, 15 min
- review the notes from last week's AI discussion
- choose one to pick up dicussion

Discuss freewrite, 45 min

AT END
- mention that next week we will start to do some work for the final
  project in class.
  - looking at sources where to find books. Where do we find books?
    - book reviews
    - spend a few minutes looking for books in book reviews, something
      relevant to information studies. 
- next week, we may have visitors in the class. They are here to see
  me teach more than you.

IF TIME:
AI advertisement activity, 20 min (10/10):
- go to website for:
  - claude, gemini, or chatgpt
- look at their promotional materials, and think about:
  - what are they selling? what ideas or desires are they using to
    sell the product.
  - how is this product intended to be used, according to the ads?
  - what surfaces for you in terms of the advertisement culture, or AI
    generally?
  - (tough one) what are the possibilities for resistance here? Is
    there anything we can do as consumers? Or do we just not use
    products?

** week 4, being, online
apple vision pro commercial
https://www.youtube.com/watch?v=TX9qSaGXFyg
mci TV add 1997: https://www.youtube.com/watch?v=ioVMoeCbrig

*** Agenda
- introductions
- discuss readings
- "preferences" persona activity
- next week we will start working on the final projects in class,
  doing some brainstorming about areas of interest

*** introductions 10:
- dream vacation spot

*** think/pair/share: 30-40 minutes
- what was one part of the reading that challenged or confused you: 2 minutes
- what was one part of the reading that compelled you or made you
  think about something differently: 2 minutes
- groups of 3 or 4: share, choose one of each to share with the class:
  5-10 minutes
- share with the class: write down on the board: 15 minutes

*** discuss as a class: 30-45 minutes

*** IF TIME:
- Let's try to sketch out the different views each of these writers
  have on "being online". What are the main arguments for each? 

*** Readings:

Donna Haraway, “A Cyborg Manifesto: Science, Technology, and
Socialist-Feminism in the Late Twentieth Century,” from Simians,
Cyborgs, and Women: The Reinvention of Nature. 1989. pp. 149-181.
- What does the *cyborg figure* enable Haraway to do? What does it
  allow her to signify or represent?
  - a mix of ideas, theories, even those taken from oppressive
    paradigms like the "informatics of domination"
  - "illegitimate offspring" (151).
  - probably the most useful thing about the cyborg figure, is that it
    is a pastiche, mixture, and allows us to take things that were
    created to oppress or to exploit, to separate and partition, and
    use them for creating new kinds of collectivities, communities,
    affinity-based solidarities.
- Critique of feminism: different feminisms have sought a kind of
  unification of women, which in every case serves to leave some women
  out. Identity politics is a problem, because any category
  necessarily overlooks someone. 
  - marxist feminism: women unified by an idea of labor.
  - radical feminism: women unified by sexualization/objectificaiton.
  - Haraway says that these unifications are totalizing, applying one
    definition to account for all women, which leaves out those
    already on the margins:
    - second wave feminism left out working class women, largely women
      of color, who were already in the workforce.
- "Informatics of Domination"
  - how power structures and paradigms are shifting over time, a
    problem but also an opportunity. 
  - new models for control in the networked age:
    - eugenics -> population control
    - race -> economic development
  - women are now in the "integrated circuit", in the "homework
    economy," poverty has been feminized.
- Language: a "problem of coding"
  - we do not want universal translation.
    - we are already cyborgs, the question is will we harness our
      partiality for resisiting domination, rather than submitting to
      exploitative and consumptive power? 
  - "irony", "blasphemy":
    - saying things that are not expected,
    - perverting something meant to be sacred. 

Nakamura. “Syrian Lesbian Bloggers, Fake Geishas, and the Attractions
of Identity Tourism,” Hyphen: Asian America Unabridged, July 2011
- idea of "*identity tourism*" - trying on an exotic / unfamiliar
  identity in online spaces.
- Why did they impersonate lesbians?
  - "Getting strangers to talk to you and give you attention is much
    easier when you’re an attractive lesbian Asian girl with an
    important story to tell than if you’re a frumpy white middle-aged
    graduate student, as was MacMaster"
  - "appropriating lesbian identities would give them readers and
    afford them entry to a close-knit community that they could never
    hope to penetrate in real life"
  - He says he did it to save/ advocate for the culture, which is
    often hated or denigrated for homophobia, misogeny.
    - but he plays into a history of white men speaking for brown
      women in the name of dignity, rights, equality. 

“Prologue” from N. Katherine Hayles’ How We Became Posthuman: Virtual
Bodies in Cybernetics, Literature, and Informatics, 1999:
https://press.uchicago.edu/Misc/Chicago/321460.html
- Hayles is saying that computation, technology performs the illusion
  of the body splicing from the mind -- but the mind, our thoughts,
  our intelligence, our gender, is embodied. We cannot forget that.  
- "Your job is to pose questions that can distinguish verbal
  performance from embodied reality."
- "Here, at the inaugural moment of the computer age, the erasure of
  embodiment is performed so that "intelligence" becomes a property of
  the formal manipulation of symbols rather than enaction in the human
  lifeworld."
- "Why does gender appear in this primal scene of humans meeting their
  evolutionary successors, intelligent machines? What do gendered
  bodies have to do with the erasure of embodiment and the subsequent
  merging of machine and human intelligence in the figure of the
  cyborg?"
- "The very existence of the test, however, implies that you may also
  make the wrong choice. Thus the test functions to create the
  possibility of a disjunction between the enacted and the represented
  bodies, regardless which choice you make. What the Turing test
  "proves" is that the overlay between the enacted and the represented
  bodies is no longer a natural inevitability but a contingent
  production, mediated by a technology that has become so entwined
  with the production of identity that it can no longer meaningfully
  be separated from the human subject."

Tufekci, Zeynep. (2017). “We're Building a Dystopia Just to Make
People Click on Ads.” TED. https://www.youtube.com/watch?v=iFTWM7HV2UI
- Explains how AI can affect our online experience, from 2017
  perspective.
- Makes some great points:
  - Youtube showing a vegan video after a vegetarian video. The
    algorithm keeps you there by showing you more and more hardcore
    things.
    - Something here about human attention, what we pay attention to,
      what we are drawn to.
  - Curated feeds mean that we are not seeing what other people are seeing.
    - /without a common basis of information, we cannot have real
      debate/.
    - "personalization" makes public debate impossible.
      - as was on display last Tuesday night. 

*** BREAK

*** continue discussion
*** IF TIME: Activity on Online Ads (20/30):


- visit two or more of the following:
  - https://myadcenter.google.com/
  - https://x.com/settings/your_twitter_data/twitter_interests
  - https://www.facebook.com/ads/about/?entry_product=ad_preferences
  - https://accountscenter.instagram.com/ad_preferences/
- Explore the settings on those pages, looking for records of things
  you like or things that the app thinks you will like.
  - You may have to click on things like "customize ads" or "ad
    preferences" to see your data.
- After poking around a bit, spend 10 minutes reflecting on the
  following: 
  - how surprised are you by the infromation about your preferences?
  - how accurate is the data?
  - take note of the interface that these companies use to show your
    data (what do they show, and how do they show it?). How do they
    want you to engage with this data?  

*** IF TIME: Freewrite:
- which of the perspectives from the readings most closely aligns with
  your experience of being online today?
  - For example, thinking of Donna Haraway's concept of the cyborg.
    How could you marshal the cyborg to respond to the ways that the
    ad industry operates in today's world? Or, what about Nakamura's
    point about identity tourism, which occurs online?

** week 5, governance
Goals
- discuss readings on "governance theme" - winnowing down our
  conversations to more specific frame of how information environments
  are governing and being governed by certain powers.
  - all of our work prepping us for the next several weeks, where we
    will dive into: design, archives, libraries
- critical reading skills:
  - map out some of the perspectives contained within the readings
  - grasping arguments and terminology, to understand the views in a
    more systematic way (so that we can continue to build)
    - defining terms and main ideas from each of the readings.
- start to brainstorm book review project toward the end of class.
- next week, we will start talking about design, then archives. 

Agenda
- introductions:
  - name, favorite disney character 
- what was one part of the reading that was confusing or you didn't
  quite understand: 20-30 min
  - write for 5 minutes
  - share and discuss for 15 minutes
- what was something from the reading that you found interesting? Why
  was it interesting? 30
  - write for 5-10 minutes
  - small group for 10-15 min
  - share with the class 15 min
- if time: start discussion, 15-30 minutes
 - define some key terms from each of these authors
      - surveillance capitalism
      - new jim code
      - big other
      - open evolution
      - universal standing
- BREAK
- continue discussion, going down the list of questions, 30 min
  - from last week: "What shifts in the culture have made people okay
    with “ad-surveillance” technology?"
  - mapping out the positions
    - Write out their positions in one or two sentences.
      - benjamin: current tech perpetuates old racial / economic divisions
      - zuboff: current tech creates a new system of surveillance
        capitalism that replaces market capitalism
      - lessig: current tech needs to maintain its open source
        principles if it is to remain open and accessible to all
- brainstorming final projects: 30 min
  - freewrite: 10 minutes
    - From the past month, what are some of the class conversations or
      ideas from the reading that you found most compelling?
      - what about these did you find interesting?
      - then, identify 2 or 3 keywords or key phrases associated with your interest.
  - Share with a partner, 5 minutes
  - Share as a class, making a list of keywords on the board.

*** readings
**** Ruha Benjamin - Introduction, from Race After Technology: Abolitionist
Tools for the New Jim Code

Talks about how technologies carry through historical prejudices about
blackness. Current society perpetuates racism by transforming it into
ever new tools, in this case, data gathering and surveillance, machine
learning.

technology extends racism and anti-Black violence, a paradigm she
calls “the New Jim Code”: “the employment of new technologies that
reflect and reproduce existing inequities but that are promoted and
perceived as more objective or progressive than the discriminatory
systems of a previous era” (5-6).

"The New Jim Code" - "the employment of new technologies that reflect
and reproduce existing inequalities but that are promoted and
perceived as more objective or progressive than the discriminatory
systems of a previous era" (3).
- some names are "normal" (neutral) in our society. That just means
  they are unmarked.
- the term "code" here means something specific. It means information,
  markup, about a person. "Codes are both reflective and predictive".
  They indicate the way that a person will be treated. 

The values that drive tool production -- objectivity, profitability --
are inherently racist:
- “Far from coming upon a sinister story of racist programmers
  scheming in the dark corners of the web, we will find that the
  desire for objectivity, efficiency, profitability, and progress
  fuels the pursuit of technical fixes across many different social
  arenas. Oh, if only there were a way to slay centuries of racial
  demons with a social justice bat! But, as we will see, the road to
  inequity is paved with technical fixes” (7).
- “The animating force of the New Jim Code is that tech designers
  encode judgments into technical systems but claim that the racist
  results of their designs are entirely exterior to the encoding
  process” (11-12).
- “With emerging technologies we might assume that racial bias will be
  more scientifically rooted out. Yet, rather than challenging or
  overcoming the cycles of inequity, technical fixes too often
  reinforce and even deepen the status quo” (3).
- “The animating force of the New Jim Code is that tech designers
  encode judgments into technical systems but claim that the racist
  results of their designs are entirely exterior to the encoding
  process” (6).

  → are tools good or bad in themselves? I have believed in the past
  that tools can be used in good or bad ways. That it was about
  agency, activity, discovery, performance. But it seems that tools
  themselves contain biases. What is the role of human agency in using
  biased tools?

Our current tools perpetuate old biases:
- This is meant as an extension of New Jim Crow, which argues that
  current society perpetuates racism by criminalizing it, war on
  drugs, mass incarceration. It diverts racist action into new forms.
  The newest form of this diversion is technology.
- “the language of “progress” is too easily weaponized against those
  who suffer most under oppressive systems” (4).
- “These tech advances are sold as morally superior because they
  purport to rise above human bias, even though they could not exist
  without data produced through histories of exclusion and
  discrimination” (5).

Race is a technology, a tool: 
- “This field guide explores not only how emerging technologies hide,
  speed up, or reinforce racism, but also how race itself is a kind of
  technology – one designed to separate, stratify, and sanctify the
  many forms of injustice experienced by members of racialized groups,
  but one that people routinely reimagine and redeploy to their own
  ends” (19).
- “this text presents a case for understanding race itself as a kind
  of tool – one designed to stratify and sanctify social injustice as
  part of the architecture of everyday life” (9).

Being marked, named:
- “Invisibility, with regard to Whiteness, offers immunity. To be
  unmarked by race allows you to reap the benefits but escape
  responsibility for your role in an unjust system” (2).
- “The view that “technology is a neutral tool” ignores how race also
  functions like a tool, structuring whose literal voice gets embodied
  in AI. In celebrating diversity, tokenistic approaches to tech
  development fail to acknowledge how the White aesthetic colors AI.
  The “blandness” of Whiteness that some of my students brought up
  when discussing their names is treated by programmers as normal,
  universal, and appealing” (15).

  → white people want tech to make them invisible. The opposite
  impulse has to employ the body, prioritize the marked body. Make the
  body hypervisible and open to vulnerability.

  → Wendy Chun’s image of the window. The screen goes both ways. You
  are already being seen when you use technology.

**** Zuboff, S. (2015). Big other: Surveillance Capitalism and the
Prospects of an Information Civilization. Journal of Information
Technology, 30(1), 75-89. https://doi.org/10.1057/jit.2015.5

This is a perspective from 2015, how does this compare to Ruha
Benjamin writing about race in 2021? (Benjamin would say that
rather than a break with the past, we are doing more of the same). 

What about the terminology here, what does it give us that others
don't? 

- "surveillance capitalism"
  - "unexpected and often illegible mechanisms of extraction,
    commodification, and control that effectively exile persons from
    their own behavior while producing new markets of behavioral
    prediction and modification."
  - from "market capitalism" to "surveillance capitalism"

- "big other" - "a ubiquitous networked institutional regime that
  records, modiﬁes, and commodiﬁes everyday experience from toasters
  to bodies, communication to thought, all with a view to establishing
  new pathways to monetization and proﬁt. Big Other is the sovereign
  power of a near future that annihilates the freedom achieved by the
  rule qof law." (81)

  --> how would Ruha Benjamin respond to this?

- "informate" - the ability of a machine to produce information while
  carrying out instructions. It turns normal activities into an
  "electronic text". 

- "logic of accumulation" which underlies technological tools like
  Google search. There's an old desire to incorporate more and more
  machines to "enable more continuity and control," and this
  development has led to not only efficient work but also the
  production of more information, which can then be further analyzed,
  and used to automate, optimize, etc.

  -> "logic of accumulation" is one of those things that contribute to
  notions of "objectivity" and "efficiency" which we so value in our
  tools, and which, according to Benjamin, perpetuate racism.

- Takes us on a point by point reading of google exec identifying
  "four uses" of computation, showing how these create a new kind of
  capitalism that's called "surveillance capitalism"
  - data (quantity over quality) extraction (one way relationship) and
    analysis,’
    - rather than raising wages with profits, the employee is more
      distanced from the employer.
    - The assets are "surveillance assets", they are taken from users
      often without their knowledge

      -> isn't this is like the plundering of natural resources,
      whereas now we are plundering human attention?
  - ‘new contractual forms due to better monitoring,’
    - they are actually creating new rules around privacy. Going
      around and extracting data until they are stopped. How they got
      "Street View". (And how ChatGPT was created, too).
      - "New possibilities of subjugation are produced as this
        innovative institutional logic thrives on unexpected and
        illegible mechanisms of extraction and control that exile
        persons from their own behavior" (85).
  - ‘personalization and customization,'
  - 'continuous experiments.

**** Lessig, Lawrence. (1999). “Open code and open societies: values of
internet governance,” Chicago-Kent Law Review 74, 101–116.
https://cyber.harvard.edu/works/lessig/final.P

- How do we read this today?
  - All you need to connect to a URL is an IP address. That's all.
  - "Nothing requires that the other side learn anything real about
    you" (103).

page 104: code implies values, defines space:
- the code now protects privacy, but this won't always be the case,
  because commerce does not like privacy.
- "engineers are governors" (104).

The internet is a product of a very specific history
- started as a defense project, money to build up security
- moved to an academic research project
- made with open standards like HTML and HTTP

A network can only grow if it is open (which means that all companies
trying to make money off of it are profiting from open/free
resources).

Values encoded into open source:
- "Open-Evolution" - things are built on a minimal structure so that
  they can grow in multiple directions. "Do not play god". "Keep the
  core simple".
  - "modularity" - not about just efficiency or transparency, but
    "permits code to be modified; it permits one part to be
    substituted for another" (111).
  - "jurisdiciton" - decentralized; so change comes from the masses,
    from the bottom up. No one person can control the development.
- "Universal Standing" - it is open so that anyone can work on it,
  improve it. Not like politics that's only open to the crazies and
  the rich.
  - free to entry
  - the foundation of the internet as a commons
**** DW Documentary (2022). “Fake News, Propaganda, and Conspiracy Theories,” YouTube, https://www.youtube.com/watch?v=HDtFpGfORpE 
- how information/disinformation has spread across major "superpower"
  countries. A little different in each, but same effect: to mobilize
  large groups of people that previously had not been mobilized.
  - Countries like Russia and China, the government is driving the spread
  - Countries like USA and the EU, conspiracy theorists are driving
    the spread

** week 6

** week 7

** week 8

** week 9 

** week 10

** week 11

** week 12

** week 13

** week 14

